{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to use the `check_conversion` function to verify successful conversion to ONNX. This function wraps the `check_model` and `create_input` modules found in the source code of OLive (ONNX Go Live) service. https://github.com/microsoft/OLive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will demonstrate step-by-step how to use the model trained in the [Sklearn tutorial notebook](https://github.com/factoryofthesun/IVaps/blob/master/examples/Sklearn_Iris_Conversion_Simulation_and_Estimation.ipynb) to (1) generate test data, (2) save the data as .pb files in the proper directory structure, and (3) confirm successful conversion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing test data files\n",
    "\n",
    "#### Expected folder structure\n",
    "\n",
    "First you'll need to prepare your model and test data files. Supported model frameworks are - cntk, coreml, keras, scikit-learn, tensorflow and pytorch. \n",
    "\n",
    "Test data are used for a quick verification of correctness for the converted model. This is strongly encouraged. However if no input files are provided, the `check_conversion` function will randomly generate dummy inputs for you if possible.\n",
    "\n",
    "You can put your test data in one of - \n",
    "\n",
    "  1) Your input folder with your model from another framework.\n",
    "  \n",
    "  2) Your output folder created in advance to hold your converted ONNX model.\n",
    "  \n",
    "  3) Any other location. Need to specify the path with the `test_input_path` parameter in `check_conversion`.\n",
    "  \n",
    "The best practice to put your input model file(s) and test data(optional) is **2)**. By putting test_data_sets in the \"output\" folder instead of the \"input\" folder, this approach avoids copying files in the backend. The suggested folder structure is as below:\n",
    "\n",
    "    - your_input_folder\n",
    "       - model_file(s)\n",
    "    - your_output_folder_to_hold_onnx_file\n",
    "       - test_data_set_0\n",
    "           - input_0.pb\n",
    "           - ...\n",
    "           - output_0.pb\n",
    "           - ...\n",
    "       - test_data_set_1\n",
    "           - ...\n",
    "       ...\n",
    "       - (your .onnx file after running \"convert_to_onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Test Data to ONNX pb \n",
    "\n",
    "ONNX .pb files are expected for test data. However, `IVaps` also provides a wrapper function `convert_data_to_pb` to convert pickle data to pb. Dump your input data to a single pickle file in the following dict format - \n",
    "\n",
    "    {\n",
    "        \"input_name_0\": input_data_0,\n",
    "        \"input_name_1\": input_data_1, \n",
    "        ...\n",
    "    }\n",
    "    \n",
    "or if dumping output data - \n",
    "\n",
    "    {\n",
    "        \"output_name_0\": output_data_0,\n",
    "        \"output_name_1\": output_data_1, \n",
    "        ...\n",
    "    }\n",
    "\n",
    "Then use `convert_data_to_pb` to convert your pickle file to pb files.\n",
    "\n",
    "Run convert_test_data.py to convert your pickle file. This script will read your pickle file and dump the data to a folder named \"test_data_set_0\" by default. Note that ONNX naming convention for test data folder is \"test_data_*\". Make sure to pass `--output_folder` with a folder name starting with `test_data_`. \n",
    "\n",
    "If `is_input=True`, data will be generated to `input_*.pb`s. Set `is_input` to false if you'd like to generate output pbs, in which data will be generated to `output_*.pb`s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Sklearn model and generate test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rl874/opt/anaconda3/envs/IVaps-tf/lib/python3.7/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.23.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'l1_ratio': None,\n",
       " 'max_iter': 100,\n",
       " 'multi_class': 'auto',\n",
       " 'n_jobs': None,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': None,\n",
       " 'solver': 'lbfgs',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle \n",
    "\n",
    "model = pickle.load(open(f\"models/iris_logreg.pickle\", 'rb'))\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will run inference on the raw iris data and use the outputs as the target test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97964346, 0.02035654],\n",
       "       [0.97171913, 0.02828087],\n",
       "       [0.9822502 , 0.0177498 ],\n",
       "       [0.97178867, 0.02821133],\n",
       "       [0.98207923, 0.01792077]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_out = model.predict_proba(X)\n",
    "test_out[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can save the input and output data as test files. Below is an example of saving the arrays directly to .pb files using the `numpy_helper` module from onnx. Please note that we need to set the name of our output tensor to match the output label of the ONNX model. This can easily be checked by starting up an InferenceSession with onnxruntime and checking `get_ouputs()`. The input labels can be arbitrary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['output_label', 'output_probability']\n"
     ]
    }
   ],
   "source": [
    "from onnx import numpy_helper\n",
    "import os\n",
    "\n",
    "if not os.path.exists(\"models/test_data_set_0\"):\n",
    "    os.mkdir(\"models/test_data_set_0\")\n",
    "    \n",
    "# Check output labels \n",
    "from onnxruntime import InferenceSession\n",
    "sess = InferenceSession(\"models/iris_logreg.onnx\")\n",
    "output_labels = [sess.get_outputs()[i].name for i in range(len(sess.get_outputs()))]\n",
    "print(output_labels) \n",
    "\n",
    "# Convert arrays to TensorProto, then serialize\n",
    "inp_tensor = numpy_helper.from_array(X)\n",
    "inp_tensor.name = \"input_0\"\n",
    "out_tensor = numpy_helper.from_array(test_out)\n",
    "out_tensor.name = \"output_probability\"\n",
    "\n",
    "with open('models/test_data_set_0/input_0.pb', 'wb') as f:\n",
    "    f.write(inp_tensor.SerializeToString())\n",
    "\n",
    "with open('models/test_data_set_0/output_0.pb', 'wb') as f:\n",
    "    f.write(out_tensor.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also first pickle them then convert to .pb files with the `convert_data_to_pb` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare inputs and outputs as dictionaries \n",
    "inputs = {\"input_0\":X}\n",
    "outputs = {\"output_probability\":test_out}\n",
    "\n",
    "# Pickle \n",
    "with open('data/iris_inputs.pickle', 'wb') as f:\n",
    "    pickle.dump(inputs, f)\n",
    "\n",
    "with open('data/iris_outputs.pickle', 'wb') as f:\n",
    "    pickle.dump(outputs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `ouptut_folder` is not specified for pickle conversion, then the output files will be saved in `test_data_set_0` in the current working directory. In this example, we want to save the .pb files in the same directory that the ONNX model is, the `models` subdirectory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully stored input input_0 in models/test_data_set_0/input_0.pb\n",
      "Successfully stored input output_probability in models/test_data_set_0/output_0.pb\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "from IVaps import convert_data_to_pb\n",
    "\n",
    "# Convert inputs\n",
    "convert_data_to_pb(\"data/iris_inputs.pickle\", output_folder = \"models/test_data_set_0\", is_input = True)\n",
    "# Convert outputs\n",
    "convert_data_to_pb(\"data/iris_outputs.pickle\", output_folder = \"models/test_data_set_0\", is_input = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can check our converted model using the `check_conversion` function. If we don't specify `test_input_path`, then the function will attempt to randomly generate inputs. We can also pass `log_path` if we want to save a JSON of the conversion testing log. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rl874/opt/anaconda3/envs/IVaps/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/rl874/opt/anaconda3/envs/IVaps/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/rl874/opt/anaconda3/envs/IVaps/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/rl874/opt/anaconda3/envs/IVaps/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/rl874/opt/anaconda3/envs/IVaps/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/rl874/opt/anaconda3/envs/IVaps/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data .pb files found under /Users/rl874/Documents/Tobin/IVaps/examples/models/test_data_set_0. \n",
      "Test data .pb files already exist. Skipping dummy input generation. \n",
      "\n",
      "-------------\n",
      "MODEL CORRECTNESS VERIFICATION\n",
      "\n",
      "\n",
      "Check the ONNX model for validity \n",
      "The ONNX model is valid.\n",
      "\n",
      "Check ONNX model for correctness. \n",
      "Running inference on original model with specified or random inputs. \n",
      "...\n",
      "/Users/rl874/Documents/Tobin/IVaps/examples/models/test_data_set_0\n",
      "Running inference on the converted model with the same inputs\n",
      "...\n",
      "\n",
      "Comparing the outputs from two models. \n",
      "The converted model achieves 5-decimal precision compared to the original model.\n",
      "MODEL CONVERSION SUCCESS. \n",
      "\n",
      "-------------\n",
      "MODEL CONVERSION SUMMARY\n",
      "\n",
      "{'output_onnx_path': 'models/iris_logreg.onnx', 'correctness_verified': 'SUCCESS', 'input_folder': '/Users/rl874/Documents/Tobin/IVaps/examples/models/test_data_set_0', 'error_message': ''}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rl874/opt/anaconda3/envs/IVaps/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/rl874/opt/anaconda3/envs/IVaps/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/rl874/opt/anaconda3/envs/IVaps/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/rl874/opt/anaconda3/envs/IVaps/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/rl874/opt/anaconda3/envs/IVaps/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/rl874/opt/anaconda3/envs/IVaps/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IVaps import check_conversion\n",
    "\n",
    "check_conversion(model_path = \"models/iris_logreg.pickle\", onnx_model_path = \"models/iris_logreg.onnx\", framework=\"sklearn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
