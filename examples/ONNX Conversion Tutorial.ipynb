{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook demonstrates the usage of the `convert_to_onnx` helper function for converting a model from any supported framework into ONNX for QPS inference. The function simply wraps the individual conversion functions from [ONNXMLTools](https://github.com/onnx/onnxmltools). This notebook provides examples for conversion from PyTorch, Sklearn, Keras, Tensorflow, and LightGBM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import onnxruntime as rt\n",
    "import pickle\n",
    "\n",
    "from mlisne import convert_to_onnx\n",
    "from mlisne import estimate_qps_onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general all models can be converted with the same basic function call, as demonstrated by the minimum examples below. \n",
    "\n",
    "All that is typically needed for conversion is a model, the framework string, and dummy input data. \n",
    "\n",
    "Aside from PyTorch, conversion from all other frameworks will return the converted model, which can then be sent directly into QPS estimation or an InferenceSession."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic examples: Sklearn, Keras, LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note on the dummy input data: the data can be in any format or shape as long as it is exactly how you would pass it into a model for inference. \n",
    "\n",
    "`convert_to_onnx` allows for models that take continuous and discrete inputs as separate arrays -- please refer to the Pytorch section for an in-depth example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rl874/opt/anaconda3/envs/mlisne/lib/python3.7/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.23.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00191524 0.00168807 0.00182619 0.0464512  0.0016869 ]\n"
     ]
    }
   ],
   "source": [
    "# Minimal example with Sklearn iris \n",
    "data = pd.read_csv(f\"data/iris_data.csv\")\n",
    "data = data.iloc[:,1:]\n",
    "model = pickle.load(open(f\"models/iris_logreg.pickle\", 'rb'))\n",
    "onnx = convert_to_onnx(model, \"sklearn\", data)\n",
    "# We can save the ONNX model to file as well\n",
    "onnx = convert_to_onnx(model, \"sklearn\", data, path = \"../tests/test_models/iris_test.onnx\") \n",
    "\n",
    "# We can estimate QPS/run inference directly with the converted model\n",
    "qps_skl = estimate_qps_onnx(onnx.SerializeToString(), X_c = data)\n",
    "print(qps_skl[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default input name: c_inputs\n",
      "Manual input name: new_name\n"
     ]
    }
   ],
   "source": [
    "# We can also specify a label for the ONNX input node\n",
    "convert_to_onnx(model, \"sklearn\", data, path = \"../tests/test_models/iris_test_named_node.onnx\", input_names = ('new_name',))\n",
    "\n",
    "sess1 = rt.InferenceSession(\"../tests/test_models/iris_test.onnx\")\n",
    "print(\"Default input name:\", sess1.get_inputs()[0].name)\n",
    "\n",
    "sess2 = rt.InferenceSession(\"../tests/test_models/iris_test_named_node.onnx\")\n",
    "print(\"Manual input name:\", sess2.get_inputs()[0].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/rl874/opt/anaconda3/envs/mlisne/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/rl874/opt/anaconda3/envs/mlisne/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/rl874/opt/anaconda3/envs/mlisne/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/rl874/opt/anaconda3/envs/mlisne/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/rl874/opt/anaconda3/envs/mlisne/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/rl874/opt/anaconda3/envs/mlisne/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/rl874/opt/anaconda3/envs/mlisne/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/rl874/opt/anaconda3/envs/mlisne/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/rl874/opt/anaconda3/envs/mlisne/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/rl874/opt/anaconda3/envs/mlisne/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/rl874/opt/anaconda3/envs/mlisne/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/rl874/opt/anaconda3/envs/mlisne/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/rl874/opt/anaconda3/envs/mlisne/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The ONNX operator number change on the optimization: 10 -> 6\n",
      "The maximum opset needed by this model is only 9.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 10)                50        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 83\n",
      "Trainable params: 83\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "ir_version: 4\n",
      "producer_name: \"keras2onnx\"\n",
      "producer_version: \"1.7.0\"\n",
      "domain: \"onnxmltools\"\n",
      "model_version: 0\n",
      "doc_string: \"\"\n",
      "graph {\n",
      "  node {\n",
      "    input: \"dense_1_input\"\n",
      "    input: \"dense_1/kernel:0\"\n",
      "    output: \"dense_10\"\n",
      "    name: \"dense_1\"\n",
      "    op_type: \"MatMul\"\n",
      "    doc_string: \"\"\n",
      "    domain: \"\"\n",
      "  }\n",
      "  node {\n",
      "    input: \"dense_10\"\n",
      "    input: \"dense_1/bias:0\"\n",
      "    output: \"biased_tensor_name1\"\n",
      "    name: \"Add1\"\n",
      "    op_type: \"Add\"\n",
      "    domain: \"\"\n",
      "  }\n",
      "  node {\n",
      "    input: \"biased_tensor_name1\"\n",
      "    output: \"dense_1/Relu:0\"\n",
      "    name: \"Relu\"\n",
      "    op_type: \"Relu\"\n",
      "    domain: \"\"\n",
      "  }\n",
      "  node {\n",
      "    input: \"dense_1/Relu:0\"\n",
      "    input: \"dense_2/kernel:0\"\n",
      "    output: \"dense_20\"\n",
      "    name: \"dense_2\"\n",
      "    op_type: \"MatMul\"\n",
      "    domain: \"\"\n",
      "  }\n",
      "  node {\n",
      "    input: \"dense_20\"\n",
      "    input: \"dense_2/bias:0\"\n",
      "    output: \"biased_tensor_name\"\n",
      "    name: \"Add\"\n",
      "    op_type: \"Add\"\n",
      "    domain: \"\"\n",
      "  }\n",
      "  node {\n",
      "    input: \"biased_tensor_name\"\n",
      "    output: \"dense_2\"\n",
      "    name: \"Softmax\"\n",
      "    op_type: \"Softmax\"\n",
      "    attribute {\n",
      "      name: \"axis\"\n",
      "      i: -1\n",
      "      type: INT\n",
      "    }\n",
      "    doc_string: \"\"\n",
      "    domain: \"\"\n",
      "  }\n",
      "  name: \"sequential_1\"\n",
      "  initializer {\n",
      "    dims: 10\n",
      "    dims: 3\n",
      "    data_type: 1\n",
      "    float_data: 0.2938280701637268\n",
      "    float_data: 1.5117894411087036\n",
      "    float_data: 1.301153302192688\n",
      "    float_data: 5.136831283569336\n",
      "    float_data: 5.088342666625977\n",
      "    float_data: 6.197439193725586\n",
      "    float_data: 0.044205985963344574\n",
      "    float_data: 0.6089378595352173\n",
      "    float_data: 0.8469852209091187\n",
      "    float_data: 0.17862343788146973\n",
      "    float_data: -0.3797987699508667\n",
      "    float_data: -0.6275826692581177\n",
      "    float_data: 5.357481479644775\n",
      "    float_data: 5.714192867279053\n",
      "    float_data: 5.462770462036133\n",
      "    float_data: -0.3656217157840729\n",
      "    float_data: 0.4878771901130676\n",
      "    float_data: -0.3317221403121948\n",
      "    float_data: 3.610504150390625\n",
      "    float_data: 3.977809190750122\n",
      "    float_data: 3.3524036407470703\n",
      "    float_data: 0.4723048210144043\n",
      "    float_data: -0.3717428743839264\n",
      "    float_data: 0.015568554401397705\n",
      "    float_data: 0.21000587940216064\n",
      "    float_data: -0.3780304193496704\n",
      "    float_data: 0.7465175986289978\n",
      "    float_data: 0.2633802890777588\n",
      "    float_data: 0.16934818029403687\n",
      "    float_data: -0.601990818977356\n",
      "    name: \"dense_2/kernel:0\"\n",
      "  }\n",
      "  initializer {\n",
      "    dims: 3\n",
      "    data_type: 1\n",
      "    float_data: 0.20922702550888062\n",
      "    float_data: 0.2193034440279007\n",
      "    float_data: 0.2714695334434509\n",
      "    name: \"dense_2/bias:0\"\n",
      "  }\n",
      "  initializer {\n",
      "    dims: 4\n",
      "    dims: 10\n",
      "    data_type: 1\n",
      "    float_data: 1.403967022895813\n",
      "    float_data: 7.396064281463623\n",
      "    float_data: 0.7490813136100769\n",
      "    float_data: -0.11311203241348267\n",
      "    float_data: 6.985565662384033\n",
      "    float_data: 0.3099971413612366\n",
      "    float_data: 4.962944030761719\n",
      "    float_data: -0.4338662624359131\n",
      "    float_data: -0.19727672636508942\n",
      "    float_data: -0.4619075655937195\n",
      "    float_data: 0.6736120581626892\n",
      "    float_data: 3.789710283279419\n",
      "    float_data: 0.3835712671279907\n",
      "    float_data: -0.3297440707683563\n",
      "    float_data: 3.8606414794921875\n",
      "    float_data: -0.6357419490814209\n",
      "    float_data: 1.7892625331878662\n",
      "    float_data: -0.29528844356536865\n",
      "    float_data: 0.37374523282051086\n",
      "    float_data: -0.07914149761199951\n",
      "    float_data: 0.8320314884185791\n",
      "    float_data: 4.175485134124756\n",
      "    float_data: 0.384019672870636\n",
      "    float_data: -0.31173568964004517\n",
      "    float_data: 4.727912902832031\n",
      "    float_data: -0.0005796211771667004\n",
      "    float_data: 3.0348520278930664\n",
      "    float_data: -0.06205272674560547\n",
      "    float_data: 0.6679432988166809\n",
      "    float_data: -0.08246040344238281\n",
      "    float_data: 0.43885132670402527\n",
      "    float_data: 1.1326488256454468\n",
      "    float_data: -0.07214339822530746\n",
      "    float_data: -0.2516232132911682\n",
      "    float_data: 1.5277776718139648\n",
      "    float_data: -0.26273566484451294\n",
      "    float_data: 1.2904518842697144\n",
      "    float_data: 0.4371525049209595\n",
      "    float_data: 0.2356555312871933\n",
      "    float_data: -0.5439807176589966\n",
      "    name: \"dense_1/kernel:0\"\n",
      "  }\n",
      "  initializer {\n",
      "    dims: 10\n",
      "    data_type: 1\n",
      "    float_data: 0.215406134724617\n",
      "    float_data: 1.1661919355392456\n",
      "    float_data: 0.09815250337123871\n",
      "    float_data: 0.0\n",
      "    float_data: 1.1056692600250244\n",
      "    float_data: -0.013181677088141441\n",
      "    float_data: 0.7666188478469849\n",
      "    float_data: 0.0\n",
      "    float_data: 0.03299902006983757\n",
      "    float_data: 0.0\n",
      "    name: \"dense_1/bias:0\"\n",
      "  }\n",
      "  input {\n",
      "    name: \"dense_1_input\"\n",
      "    type {\n",
      "      tensor_type {\n",
      "        elem_type: 1\n",
      "        shape {\n",
      "          dim {\n",
      "            dim_param: \"N\"\n",
      "          }\n",
      "          dim {\n",
      "            dim_value: 4\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  output {\n",
      "    name: \"dense_2\"\n",
      "    type {\n",
      "      tensor_type {\n",
      "        elem_type: 1\n",
      "        shape {\n",
      "          dim {\n",
      "            dim_param: \"N\"\n",
      "          }\n",
      "          dim {\n",
      "            dim_value: 3\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "opset_import {\n",
      "  domain: \"\"\n",
      "  version: 9\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Minimal example with Keras iris\n",
    "import keras\n",
    "\n",
    "model = keras.models.load_model(f\"models/keras_example\")\n",
    "print(model.summary())\n",
    "onnx = convert_to_onnx(model, \"keras\", data)\n",
    "print(onnx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rl874/opt/anaconda3/envs/mlisne/lib/python3.7/site-packages/lightgbm/__init__.py:48: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n",
      "The maximum opset needed by this model is only 1.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.65800154],\n",
       "       [0.45519567],\n",
       "       [0.40523195],\n",
       "       [0.4922787 ],\n",
       "       [0.34425545]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Minimal example with LightGBM\n",
    "import lightgbm as lgb\n",
    "\n",
    "data = pd.read_csv(f\"data/lgbm_regression.test\", header=None, sep='\\t')\n",
    "data = data.drop(0, axis = 1) # First column is the test Y variable\n",
    "model = lgb.Booster(model_file= f\"models/lgbm_example.txt\")\n",
    "onnx = convert_to_onnx(model, \"lightgbm\", data)\n",
    "\n",
    "# QPS estimation -- note that the return array is 2D for LightGBM \n",
    "estimate_qps_onnx(onnx.SerializeToString(), X_c = data[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LightGBM models will return predictions in a 2D array when converted to ONNX. Otherwise the outputs will be the same as inference with the original model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 1)\n",
      "(500,)\n"
     ]
    }
   ],
   "source": [
    "sess = rt.InferenceSession(onnx.SerializeToString())\n",
    "label_name = sess.get_outputs()[0].name\n",
    "input_name = sess.get_inputs()[0].name\n",
    "\n",
    "onnx_out = sess.run([label_name], {input_name: np.array(data)})[0]\n",
    "print(onnx_out.shape)\n",
    "\n",
    "og_out = model.predict(data)\n",
    "print(og_out.shape)\n",
    "\n",
    "np.testing.assert_array_almost_equal(onnx_out.flatten(), og_out, decimal = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensorflow (In progress...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will read in a pretrained model with the below framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatModel(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_size, num_numerical_cols, output_size, layers, p=0.4):\n",
    "        super().__init__()\n",
    "        self.all_embeddings = nn.ModuleList([nn.Embedding(ni, nf) for ni, nf in embedding_size])\n",
    "        self.embedding_dropout = nn.Dropout(p)\n",
    "        self.batch_norm_num = nn.BatchNorm1d(num_numerical_cols)\n",
    "\n",
    "        all_layers = []\n",
    "        num_categorical_cols = sum((nf for ni, nf in embedding_size))\n",
    "        input_size = num_categorical_cols + num_numerical_cols\n",
    "\n",
    "        for i in layers:\n",
    "            all_layers.append(nn.Linear(input_size, i))\n",
    "            all_layers.append(nn.ReLU(inplace=True))\n",
    "            all_layers.append(nn.BatchNorm1d(i))\n",
    "            all_layers.append(nn.Dropout(p))\n",
    "            input_size = i\n",
    "\n",
    "        all_layers.append(nn.Linear(layers[-1], output_size))\n",
    "\n",
    "        self.layers = nn.Sequential(*all_layers)\n",
    "\n",
    "        self.m = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x_categorical, x_numerical):\n",
    "        embeddings = []\n",
    "        for i,e in enumerate(self.all_embeddings):\n",
    "            embeddings.append(e(x_categorical[:,i]))\n",
    "        x = torch.cat(embeddings, 1)\n",
    "        x = self.embedding_dropout(x)\n",
    "\n",
    "        x_numerical = self.batch_norm_num(x_numerical)\n",
    "        x = torch.cat([x, x_numerical], 1)\n",
    "        x = self.layers(x)\n",
    "        x = self.m(x)\n",
    "\n",
    "        return x[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CatModel(\n",
       "  (all_embeddings): ModuleList(\n",
       "    (0): Embedding(3, 2)\n",
       "    (1): Embedding(2, 1)\n",
       "    (2): Embedding(2, 1)\n",
       "    (3): Embedding(2, 1)\n",
       "  )\n",
       "  (embedding_dropout): Dropout(p=0.4, inplace=False)\n",
       "  (batch_norm_num): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=11, out_features=200, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.4, inplace=False)\n",
       "    (4): Linear(in_features=200, out_features=100, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.4, inplace=False)\n",
       "    (8): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): Dropout(p=0.4, inplace=False)\n",
       "    (12): Linear(in_features=50, out_features=2, bias=True)\n",
       "  )\n",
       "  (m): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CatModel([(3, 2), (2, 1), (2, 1), (2, 1)], 6, 2, [200,100,50], p=0.4)\n",
    "model.load_state_dict(torch.load(f\"models/churn_categorical.pt\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will notice that this model takes two separate inputs, `x_categorical` and `x_numerical` for discrete and continuous variables, respectively. Our conversion function is well equipped to handle such cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in input data \n",
    "data = pd.read_csv(\"data/churn_data.csv\")\n",
    "\n",
    "# Split discrete and continuous data\n",
    "categorical_cols = ['Geography', 'Gender', 'HasCrCard', 'IsActiveMember']\n",
    "numerical_cols = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
    "\n",
    "for category in categorical_cols:\n",
    "    data[category] = data[category].astype('category')\n",
    "cat = [data[c].cat.codes.values for c in categorical_cols]\n",
    "\n",
    "cat_data = np.stack(cat, 1)\n",
    "num_data = np.array(data[numerical_cols])\n",
    "\n",
    "cat_tensor = torch.tensor(cat_data).long()\n",
    "num_tensor = torch.tensor(num_data).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch conversion is slightly different from the other frameworks in that it makes use of a package-specific `export` function. This function will not return the converted onnx model and requires a file path to save to.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For PyTorch to ONNX conversion a file path must be given.\n"
     ]
    }
   ],
   "source": [
    "# Without a file path, the conversion will throw an error\n",
    "try:\n",
    "    convert_to_onnx(model, \"pytorch\", cat_data, num_data)\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`convert_to_onnx` allows for models with up to two separate inputs. Keep in mind that the order that these inputs are passed should be the same as their order in the model's `forward` function. We can also pass input names that can be referenced during ONNX inferencing, but these are not required.\n",
    "\n",
    "Models are typically sensitive to data types, so it is important to cast the input data to the expected type before passing them into conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True True\n"
     ]
    }
   ],
   "source": [
    "# Dummy data can be in any format, as long as it is convertible to a tensor and multi-dimensional\n",
    "# The below calls will all result in the same outcome\n",
    "ret = convert_to_onnx(model, \"pytorch\", dummy_input1 = cat_data.astype(np.int64), dummy_input2 = num_data.astype(np.float32), \n",
    "                      path = \"../tests/test_models/churn_cat_test.onnx\", input_names=(\"d_inputs\", \"c_inputs\"))\n",
    "ret2 = convert_to_onnx(model, \"pytorch\", dummy_input1 = cat_data[0,np.newaxis].astype(np.int64), dummy_input2 = num_data[0,np.newaxis].astype(np.float32), \n",
    "                       path = \"../tests/test_models/churn_cat_test.onnx\", input_names=(\"d_inputs\", \"c_inputs\"))\n",
    "ret3 = convert_to_onnx(model, \"pytorch\", dummy_input1 = cat_tensor, dummy_input2 = num_tensor, \n",
    "                       path = \"../tests/test_models/churn_cat_test.onnx\", input_names=(\"d_inputs\", \"c_inputs\"))\n",
    "\n",
    "print(ret, ret2, ret3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also set the name(s) of the output node. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat_out'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_to_onnx(model, \"pytorch\", dummy_input1 = cat_tensor, dummy_input2 = num_tensor, output_names = [\"cat_out\"], \n",
    "                       path = \"../tests/test_models/churn_cat_test.onnx\", input_names=(\"d_inputs\", \"c_inputs\"))\n",
    "\n",
    "sess = rt.InferenceSession(\"../tests/test_models/churn_cat_test.onnx\")\n",
    "sess.get_outputs()[0].name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compare inference between ONNX and the original model to validate successful conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    torch_preds = model(cat_tensor, num_tensor).numpy()\n",
    "sess = rt.InferenceSession(\"../tests/test_models/churn_cat_test.onnx\")\n",
    "output_name = sess.get_outputs()[0].name\n",
    "onnx_preds = sess.run([output_name], {\"c_inputs\": num_data.astype(np.float32),\n",
    "                                      \"d_inputs\": cat_data.astype(np.int64)})[0]\n",
    "\n",
    "np.testing.assert_array_almost_equal(torch_preds, onnx_preds, decimal=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run QPS inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.30627927, 0.23923162, 0.9999994 , ..., 0.16931152, 0.10803223,\n",
       "       0.11450195], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_qps_onnx(\"../tests/test_models/churn_cat_test.onnx\", X_c = num_data.astype(np.float32), X_d = cat_data.astype(np.int64), \n",
    "                  input_type = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 6)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
