{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn Example: LogisticRegression and Iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we will train as LogisticRegression model on the iris dataset, convert it to ONNX format, simulate historical treatment data, then estimate the treatment effects using our IV estimation method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Train and Convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, X consists of 4 continuous variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dtype: float64 \n",
      "Shape: (150, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dtype:\", X.dtype, \"\\nShape:\", X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our estimation method relies on binary treatment assignment, so here let's assume that iris classifications of 1 or 2 indicate treatment recommendation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[y>0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clr = LogisticRegression()\n",
    "clr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.05205203e-04, 9.99594795e-01],\n",
       "       [9.47539986e-01, 5.24600143e-02],\n",
       "       [2.10102151e-04, 9.99789898e-01],\n",
       "       [1.35983036e-01, 8.64016964e-01],\n",
       "       [9.74173988e-01, 2.58260118e-02]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clr.predict_proba(X_test)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "# Save model\n",
    "with open(f\"models/iris_logreg.pickle\", \"wb\") as f:\n",
    "    pickle.dump(clr, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load back in the model and convert to ONNX. This step is necessary because our QPS estimation procedure only takes ONNX models for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'l1_ratio': None,\n",
       " 'max_iter': 100,\n",
       " 'multi_class': 'auto',\n",
       " 'n_jobs': None,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': None,\n",
       " 'solver': 'lbfgs',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = pickle.load(open(f\"models/iris_logreg.pickle\", 'rb'))\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mlisne package provides an ONNX conversion wrapper function that requires a dummy input and framework string to process datatypes and run the correct conversion function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlisne.helpers import convert_to_onnx\n",
    "\n",
    "X_dummy = X[0,:]\n",
    "filename = \"models/iris_logreg.onnx\"\n",
    "\n",
    "convert_to_onnx(model = model, dummy_input = X_dummy, path = filename, framework = \"sklearn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The wrapper function will also pass on any keyword arguments to the downstream conversion function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_to_onnx(model=model, dummy_input=X_dummy, path=filename, framework=\"sklearn\", target_opset=12, \n",
    "                doc_string=\"Sklearn LogisticRegression model trained on iris dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Simulate historical treatment data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's simulate treatment and non-treatment outcomes for each observation i with the following structural equations:\n",
    "\\begin{align}\n",
    "Y_{0i} &= \\mathcal{N}(2,2)x_{1i} + \\mathcal{N}(3,1)x_{2i} + \\mathcal{N}(0,3) \\\\\n",
    "Y_{1i} &= Y_{0i} + \\mathcal{N}(5,1) + \\mathcal{N}(0,1)\n",
    "\\end{align}\n",
    "\n",
    "Where $x_{1}$ and $x_{2}$ refer to the first and second variables of input X. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate coefficients for observations\n",
    "b1 = np.random.normal(2,2,len(X))\n",
    "b2 = np.random.normal(3,1,len(X))\n",
    "e0 = np.random.normal(0,3,len(X))\n",
    "treatment_effect = np.random.normal(5,1, len(X))\n",
    "e1 = np.random.normal(0,1,len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y0 = b1 * X[:,0] + b2 * X[:,1] + e0\n",
    "Y1 = Y0 + treatment_effect + e1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate treatment recommendation probabilities using our trained model. Let's assume that the treatment is assigned when the model recommends assignment 75% of the time (no-defiers assumption)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.019318  , 0.02625827, 0.01666684, 0.02640822, 0.01710709])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create treatment recommendation probabilities\n",
    "Z_probs = clr.predict_proba(X)[:,1]\n",
    "Z_probs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Draw treatment recommendations\n",
    "recommend_prob = np.random.uniform(size=len(X))\n",
    "Z = (recommend_prob <= Z_probs).astype(int)\n",
    "Z[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realized assignment follows recommended assignment 75% of the time\n",
    "treatment_prob = np.random.uniform(size=len(X))\n",
    "D = []\n",
    "for i in range(len(treatment_prob)):\n",
    "    if Z[i] == 1:\n",
    "        if treatment_prob[i] >= 0.75:\n",
    "            D.append(0)\n",
    "        else:\n",
    "            D.append(1)\n",
    "    else:\n",
    "        D.append(Z[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_data = np.stack((Y0, Y1, Z, D), axis=1)\n",
    "sim_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data = np.concatenate((sim_data, X), axis=1)\n",
    "full_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "cols = ['Y0', 'Y1', 'Z', 'D', 'X1', 'X2', 'X3', 'X4']\n",
    "df = pd.DataFrame(data = full_data, columns=cols)\n",
    "df['Y'] = df['Y1']\n",
    "df.loc[df['D']==0, 'Y'] = df.loc[df['D']==0, 'Y0']\n",
    "df.to_csv(\"data/iris_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE: 4.938243400674545\n",
      "ATET: 4.921907342614233\n",
      "LATE: 4.88420353014053\n"
     ]
    }
   ],
   "source": [
    "# Treatment effects \n",
    "ate = (df.Y1 - df.Y0).mean()\n",
    "atet = (df.loc[df['D'] == 1, 'Y1'] - df.loc[df['D'] == 1, 'Y0']).mean()\n",
    "late = (df.loc[(df['D'] == df['Z']), 'Y1'] - df.loc[(df['D'] == df['Z']), 'Y0']).mean()\n",
    "print(f\"ATE: {ate}\")\n",
    "print(f\"ATET: {atet}\")\n",
    "print(f\"LATE: {late}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. QPS Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the simulated historical data into our EstimatorDataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlisne.dataset import EstimatorDataset\n",
    "from mlisne.qps import estimate_qps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data can be loaded upon initialization with optional variable indices, as well as indiviudally post-initialization. \n",
    "\n",
    "Variables without indices will be inferred to be ordered as follows: [Y, Z, D, X_d, X_c], where X_d is the set of discrete input variables, and X_c is the set of continuous input variables. \n",
    "\n",
    "For this example, our input data is all continuous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13.09555636, 17.13767785, 16.67381797, 18.46146531, 32.84339348])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iv_data = EstimatorDataset(data=df.drop(['Y0', 'Y1'], axis=1), Z=0, D=1, X_c = range(2,6))\n",
    "iv_data.Y[:5] # Y inferred as last column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13.09555636, 17.13767785, 16.67381797, 18.46146531, 32.84339348])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Overwrite data post-initialization\n",
    "iv_data.load_data(Y = df['Y'], D = df['D'])\n",
    "iv_data.Y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(150, 0), dtype=float64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Discrete data is empty\n",
    "iv_data.X_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now estimate QPS using our IV dataset and converted ONNX model. \n",
    "\n",
    "**Important:** to allow for cross-framework compatibility, our qps estimation function only works with ONNX models that take single inputs or separate continuous/discrete inputs with specified node names, and outputs with name \"output_probability\". The convert_to_onnx function will output with those settings automatically, but please keep this in mind if you plan on using an externally generated ONNX model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03226412, 0.04161337, 0.03315811, 0.04031405, 0.0291432 ])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qps = estimate_qps(iv_data, S=100, delta=0.8, ML_onnx=filename)\n",
    "qps[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The converted ONNX model sets expected input dtypes according to the dummy input, but you can also pass the continuous/discrete datatypes explicitly as a tuple to coerce the input data to a specific type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iv_data.X_c.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03820143, 0.04776963, 0.03259791, 0.04177242, 0.02697258])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qps = estimate_qps(iv_data, S=100, delta=0.8, ML_onnx=filename, types=(np.float64, np.float64))\n",
    "qps[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Treatment effect estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now estimate LATE using our IV approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlisne.estimator import TreatmentEffectsEstimator\n",
    "\n",
    "est = TreatmentEffectsEstimator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will fit on 150 values out of 150 from the dataset for which the QPS estimation is nondegenerate.\n"
     ]
    }
   ],
   "source": [
    "est.fit(iv_data, qps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treatment effect estimate: 13.865922193168899\n",
      "True LATE: 4.88420353014053\n"
     ]
    }
   ],
   "source": [
    "b0, b1, b2 = est.coef\n",
    "print(\"Treatment effect estimate:\", b1)\n",
    "print(\"True LATE:\", late)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fitted estimator also provides other estimation diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+----------+---------+---------+----------+----------+\n",
      "|           | Parameter | Std. Err |  T-Stat | P-Value | Lower CI | Upper CI |\n",
      "+-----------+-----------+----------+---------+---------+----------+----------+\n",
      "|   const   |   18.782  |  1.3041  | 14.4028 |   0.0   | 16.2051  |  21.359  |\n",
      "| Treatment |  13.8659  |  2.6641  |  5.2047 |   0.0   |  8.6013  | 19.1305  |\n",
      "|    QPS    |  -4.0282  |  2.3783  | -1.6937 |  0.0924 | -8.7281  |  0.6717  |\n",
      "+-----------+-----------+----------+---------+---------+----------+----------+\n"
     ]
    }
   ],
   "source": [
    "print(est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First stage coefficients: [ 0.0141526  0.9069103 -0.1491705]\n",
      "First stage p-values: [0.00389134 0.         0.02094199]\n",
      "First stage r2: 0.5456202817448683\n"
     ]
    }
   ],
   "source": [
    "# First stage details\n",
    "fs = est.firststage\n",
    "\n",
    "print(\"First stage coefficients:\", fs['coef'])\n",
    "print(\"First stage p-values:\", fs['p'])\n",
    "print(\"First stage r2:\", fs['r2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+----------+---------+---------+----------+----------+\n",
      "|                   | Parameter | Std. Err |  T-Stat | P-Value | Lower CI | Upper CI |\n",
      "+-------------------+-----------+----------+---------+---------+----------+----------+\n",
      "|       const       |   0.0142  |  0.0048  |  2.9333 |  0.0039 |  0.0046  |  0.0211  |\n",
      "| ML Recommendation |   0.9069  |  0.057   | 15.9122 |   0.0   |  0.7943  |  0.9894  |\n",
      "|        QPS        |  -0.1492  |  0.0639  | -2.3342 |  0.0209 | -0.2755  | -0.0567  |\n",
      "+-------------------+-----------+----------+---------+---------+----------+----------+\n"
     ]
    }
   ],
   "source": [
    "est.firststage_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
